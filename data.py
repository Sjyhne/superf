import os
import torch
import numpy as np
import cv2
import torch.nn.functional as F
import json
from pathlib import Path
import random
import glob

import tifffile

def get_and_standardize_image(image):
    """Get and standardize image to have zero mean and unit std for each channel"""
    # Check if image has a channel dimension
    if image.dim() >= 3:
        # Calculate mean and std along spatial dimensions only (not across channels)
        # For [C, H, W] format
        if image.dim() == 4:
            mean = image.mean(dim=(1, 2, 3), keepdim=True)
            std = image.std(dim=(1, 2, 3), keepdim=True)
        # For [H, W, C] format
        else:
            mean = image.mean(dim=(0, 1, 2), keepdim=True)
            std = image.std(dim=(0, 1, 2), keepdim=True)
    else:
        # For grayscale without channel dimension
        mean = image.mean()
        std = image.std()
    
    # Avoid division by zero
    std = torch.clamp(std, min=1e-8)
    
    return (image - mean) / std, mean, std

def get_dataset(args, name='satburst', keep_in_memory=True):
    """ Returns the dataset object based on the name """
    if name == 'satburst_synth':
        return SRData(data_dir=args.root_satburst_synth, num_samples=args.num_samples, keep_in_memory=keep_in_memory, scale_factor=args.scale_factor)
    elif name == 'burst_synth':
        return SyntheticBurstVal(
            data_dir=args.root_burst_synth,
            sample_id=args.sample_id,
            keep_in_memory=keep_in_memory,
            scale_factor=getattr(args, 'scale_factor', 4),
            df=getattr(args, 'df', 4),
        )
    elif name == 'worldstrat_test':
        return WorldStratTestDataset(
            data_root=getattr(args, 'root_worldstrat_test', 'worldstrat_test_data'),
            sample_id=getattr(args, 'sample_id', None),
            scale_factor=getattr(args, 'df', 4),
            keep_in_memory=keep_in_memory,
        )
    else:
        raise ValueError(f"Invalid daaset name: {name}")


class SRData(torch.utils.data.Dataset):
    def __init__(self, data_dir, num_samples, keep_in_memory=True, scale_factor=4):
        """
        Initialize SR dataset from generated data directory.
        
        Args:
            data_dir: Base path to data directory
            mode: 'lr' or 'hr' - which dataset to load
        """
        self.data_dir = Path(data_dir)
        self.keep_in_memory = keep_in_memory
        self.num_samples = num_samples
        
        # Load transformation log
        with open(self.data_dir / "transform_log.json", 'r') as f:
            self.transform_log = json.load(f)
            
        # Get list of sample names
        self.samples = sorted(list(self.transform_log.keys()))
        self.samples = self.samples[:num_samples]

        self.means = list()
        self.stds = list()
        self.lr_image_sizes = list()

        if self.keep_in_memory:
            self.images = {}
            for sample in self.samples:
                img_path = self.data_dir / self.transform_log[sample]['path']
                img = cv2.imread(str(img_path))
                img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
                img = torch.from_numpy(img).float() / 255.0
                img, mean, std = get_and_standardize_image(img)
                self.lr_image_sizes.append(img.shape[1:3])
                self.images[sample] = {
                    "image": img,
                    "mean": mean,
                    "std": std
                }

        # Load original image for reference
        self.original = cv2.imread(str(self.data_dir / "hr_ground_truth.png"))
        self.original = cv2.cvtColor(self.original, cv2.COLOR_BGR2RGB)
        self.original = (torch.from_numpy(self.original).float() / 255.0).cuda()
        # Standardize original image to have zero mean and no bias

        self.hr_coords = np.linspace(0, 1, self.original.shape[0], endpoint=False)
        self.hr_coords = np.stack(np.meshgrid(self.hr_coords, self.hr_coords), -1)
        self.hr_coords = torch.FloatTensor(self.hr_coords).cuda()

        self.lr_coords = np.linspace(0, 1, self.lr_image_sizes[0][0], endpoint=False)
        self.lr_coords = np.stack(np.meshgrid(self.lr_coords, self.lr_coords), -1)
        self.lr_coords = torch.FloatTensor(self.lr_coords).cuda()

        self.scale_factor = [scale_factor]

    def __len__(self):
        return len(self.samples)
    
    def get_input_coordinates(self):
        scale_factor = random.choice(self.scale_factor)

        input_coordinates = np.linspace(0, 1, int(self.lr_image_sizes[0][0] * scale_factor), endpoint=False)
        input_coordinates = np.stack(np.meshgrid(input_coordinates, input_coordinates), -1)
        input_coordinates = torch.FloatTensor(input_coordinates).cuda()
        return input_coordinates, scale_factor
    
    def __getitem__(self, idx):
        sample_name = self.samples[idx]
        sample_info = self.transform_log[sample_name]
        sample_id = int(sample_name.split("_")[-1])

        input_coordinates, scale_factor = self.get_input_coordinates()

        if self.keep_in_memory:
            img = self.images[sample_name]["image"]
            mean = self.images[sample_name]["mean"]
            std = self.images[sample_name]["std"]
        else:
            # Load transformed image
            img_path = self.data_dir / sample_info['path']
            img = cv2.imread(str(img_path))
            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
            img = torch.from_numpy(img).float() / 255.0
            img, mean, std = get_and_standardize_image(img)
        
        return {
            'input': input_coordinates,
            'lr_target': img,
            'scale_factor': scale_factor,
            'mean': mean,
            'std': std,
            'sample_id': sample_id,
            'shifts': {
                'dx_lr': sample_info['dx_pixels_lr'],
                'dy_lr': sample_info['dy_pixels_lr'],
                'dx_hr': sample_info['dx_pixels_hr'],
                'dy_hr': sample_info['dy_pixels_hr'],
                'dx_percent': sample_info['dx_percent'],
                'dy_percent': sample_info['dy_percent']
            }
        }
    
    def get_original_hr(self):
        """Return the original image (before any transformations)"""
        return self.original
    

    def get_lr_sample(self, index):
        """Get a specific LR sample by index.
        
        Args:
            index: Sample index (0 is the reference sample)
            
        Returns:
            Tensor of shape [C, H, W] with values in [0, 1]
        """

        if self.keep_in_memory:
            img = self.images[self.samples[index]]["image"]
            mean = self.images[self.samples[index]]["mean"]
            std = self.images[self.samples[index]]["std"]
            # Unstandardize the image
            img = img * std + mean
        else:
            sample_path = self.data_dir / f"sample_{index:02d}.png"
            img = cv2.imread(str(sample_path))
            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
            img = torch.from_numpy(img).float() / 255.0

        return img

    def get_lr_mean(self, index):
        return self.images[self.samples[index]]["mean"]

    def get_lr_std(self, index):
        return self.images[self.samples[index]]["std"]

    def get_hr_coordinates(self):
        """Return the high-resolution coordinates."""
        return self.hr_coords


class SyntheticBurstVal(torch.utils.data.Dataset):
    def __init__(self, data_dir, sample_id, keep_in_memory=True, scale_factor=4, df=4):
        """
        Initialize SyntheticBurstVal dataset.
        
        Args:
            data_dir: Base path to SyntheticBurstVal directory
            sample_id: ID of the burst to use (0-299)
            keep_in_memory: Whether to load all images into memory
        """
        self.data_dir = Path(data_dir)
        self.keep_in_memory = keep_in_memory
        self.sample_id = sample_id

        self.rggb = True

        self.scale_factor = scale_factor
        self.df = df
        
        # Format sample_id as a 4-digit string with leading zeros
        self.sample_id_str = f"{int(sample_id):04d}"
        
        # Set up paths
        self.gt_dir = self.data_dir / "gt" / self.sample_id_str
        self.burst_dir = self.data_dir / "bursts" / self.sample_id_str
        
        # Find all burst images
        self.burst_paths = sorted(list(self.burst_dir.glob('im_raw_*.png')))
        self.burst_size = len(self.burst_paths)
        
        # Extract frame indices from filenames
        self.frame_indices = []
        for path in self.burst_paths:
            # Extract the frame index from the filename (im_raw_XX.png)
            frame_idx = int(path.stem.split('_')[-1])
            self.frame_indices.append(frame_idx)
        
        # Load ground truth image
        if self.keep_in_memory:
            self.burst_images = {}
            for idx in self.frame_indices:
                img = self._read_burst_image(idx)
                img_std, mean, std = get_and_standardize_image(img)
                self.burst_images[idx] = {
                    "image": img_std,
                    "mean": mean,
                    "std": std
                }
            self.gt_image = self._read_gt_image()
            
        else:
            self.gt_image = None
            self.burst_images = None
        
        # Create coordinate grid for HR image
        if self.keep_in_memory:
            h, w = self.gt_image.shape[:-1]
            coords_h = np.linspace(0, 1, h, endpoint=False)
            coords_w = np.linspace(0, 1, w, endpoint=False)
            coords = np.stack(np.meshgrid(coords_h, coords_w), -1)
            self.hr_coords = torch.FloatTensor(coords)
        else:
            self.hr_coords = None
        
    def __len__(self):
        return self.burst_size
    
    def _read_burst_image(self, frame_idx):
        """Read a single raw burst image"""
        path = self.burst_dir / f"im_raw_{frame_idx:02d}.png"
        im = cv2.imread(str(path), cv2.IMREAD_UNCHANGED)
        # Convert from 16-bit to float and normalize
        im_t = im.astype(np.float32) / (2**14)

        # Extract RGGB channels
        R = im_t[..., 0]
        G1 = im_t[..., 1]
        G2 = im_t[..., 2]
        B = im_t[..., 3]
        
        # Average the two green channels
        G = (G1 + G2) / 2
        
        # Create RGB image
        rgb = np.stack([R, G, B], axis=-1)
        
        # Apply white balance (example values, actual values might differ)
        wb_gains = np.array([2.0, 1.0, 1.5])  # R, G, B gains
        rgb = rgb * wb_gains
        
        # Apply gamma correction
        gamma = 2.2
        rgb = np.power(np.maximum(rgb, 0), 1.0/gamma)
        
        # Clip values to [0, 1]
        rgb = np.clip(rgb, 0, 1)

        rgb = torch.from_numpy(rgb).float()
        
        return rgb
    
    def _read_gt_image(self):
        """Read the ground truth RGB image"""
        path = self.gt_dir / "im_rgb.png"
        gt = cv2.imread(str(path), cv2.IMREAD_UNCHANGED)
        # Convert from 16-bit to float and normalize
        gt_t = gt.astype(np.float32) / (2**14)

        wb_gains = np.array([2.0, 1.0, 1.5])  # R, G, B gains
        gt_t = gt_t * wb_gains

        # Apply gamma correction
        gamma = 2.2
        gt_t = np.power(np.maximum(gt_t, 0), 1.0/gamma)

        gt_t = np.clip(gt_t, 0, 1)

        gt_t = torch.from_numpy(gt_t).float()

        # resize the image to match df * lr_image_size for torch tensor
        gt_t = torch.nn.functional.interpolate(gt_t.unsqueeze(0).permute(0, 3, 1, 2), size=(int(self.burst_images[0]["image"].shape[0] * self.df), int(self.burst_images[0]["image"].shape[1] * self.df)), mode='bilinear', align_corners=False).squeeze(0)

        return gt_t.permute(1, 2, 0)
    
    def __getitem__(self, idx):
        """Get a specific frame from the burst"""
        # Get the frame index for this position
        frame_idx = self.frame_indices[idx]
        
        # Load the burst image (or get from cache)
        if self.keep_in_memory and self.burst_images is not None:
            img = self.burst_images[frame_idx]["image"]
            mean = self.burst_images[frame_idx]["mean"]
            std = self.burst_images[frame_idx]["std"]
        else:
            # Load and standardize on demand
            img = self._read_burst_image(frame_idx)
            img, mean, std = get_and_standardize_image(img)

        # Return in a format similar to SRData
        return {
            'input': self.get_hr_coordinates(),
            'lr_target': img,
            'mean': mean,
            'std': std,
            'sample_id': idx,
            'burst_id': self.sample_id,
            'scale_factor': self.scale_factor,
            'shifts': {
                'dx_percent': 0.0,  # Placeholder
                'dy_percent': 0.0   # Placeholder
            }
        }
    
    def get_burst(self):
        """Get all frames from the burst as a tensor [N, C, H, W]"""
        if self.keep_in_memory and self.burst_images is not None:
            # Use cached images
            burst = [self.burst_images[idx]["image"] for idx in self.frame_indices]
        else:
            # Load images on demand
            burst = []
            for idx in self.frame_indices:
                img = self._read_burst_image(idx)
                img_std, _, _ = get_and_standardize_image(img)
                burst.append(img_std)
        return torch.stack(burst, 0)
    
    def get_original_hr(self):
        """Return the ground truth image"""
        if self.keep_in_memory and self.gt_image is not None:
            return self.gt_image
        else:
            return self._read_gt_image()
    
    def get_lr_sample(self, frame_idx=0):
        """Get a specific LR frame from the burst"""
        if self.keep_in_memory and self.burst_images is not None:
            # Make sure frame_idx is in range
            if frame_idx >= len(self.frame_indices):
                frame_idx = 0
            idx = self.frame_indices[frame_idx]
            img = self.burst_images[idx]["image"]
            mean = self.burst_images[idx]["mean"]
            std = self.burst_images[idx]["std"]
            # Unstandardize the image
            img = img * std + mean
            return img
        else:
            return self._read_burst_image(self.frame_indices[frame_idx])
    
    def get_lr_mean(self, frame_idx=0):
        return self.burst_images[self.frame_indices[frame_idx]]["mean"]

    def get_lr_std(self, frame_idx=0):
        return self.burst_images[self.frame_indices[frame_idx]]["std"]
    
    def get_hr_coordinates(self):
        """Return coordinates for the HR image"""
        if self.hr_coords is not None:
            return self.hr_coords
            
        # Create on demand if not cached
        gt = self._read_gt_image()
        h, w = gt.shape[1:]
        coords_h = np.linspace(0, 1, h, endpoint=False)
        coords_w = np.linspace(0, 1, w, endpoint=False)
        coords = np.stack(np.meshgrid(coords_h, coords_w), -1)
        return torch.FloatTensor(coords)



class WorldStratDatasetFrame(torch.utils.data.Dataset):
    """ Returns single LR frames in getitem """
    def __init__(self, data_dir, area_name="UNHCR-LBNs006446", num_frames=8, hr_size=None):
        """
        Args:
            data_dir (str): Path to the dataset.
            area_name (str): area name.
        """

        self.dataset_root = '/home/nlang/data/worldstrat_kaggle'
        self.hr_dataset = "{}/hr_dataset/12bit".format(data_dir)
        self.lr_dataset = "{}/lr_dataset".format(data_dir)
        #self.metadata_df = pd.read_csv("{}/metadata.csv".format(dataset_root))

        self.area_name = area_name
        self.num_frames = num_frames    
        self.hr_size = hr_size

        # Load high-resolution image
        self.hr_image = self.get_hr()   # Shape: (hr_img_size, hr_img_size, 3)
        if self.hr_size is not None:
            self.hr_image = cv2.resize(self.hr_image, (self.hr_size, self.hr_size), interpolation=cv2.INTER_AREA)
        self.hr_image = torch.tensor(self.hr_image)
        

        # Create input coordinate grid that matches the HR image
        self.hr_coords = np.linspace(0, 1, self.hr_image.shape[0], endpoint=False)
        self.hr_coords = np.stack(np.meshgrid(self.hr_coords, self.hr_coords), -1)
        self.hr_coords = torch.FloatTensor(self.hr_coords)
    
    def __len__(self):
        # TODO
        return self.num_frames
    
    def get_hr(self):
        """Loads and processes the high-resolution image."""
        hr_rgb_path = os.path.join(self.hr_dataset, self.area_name, f"{self.area_name}_rgb.png")
        print(hr_rgb_path)
        hr_rgb_img = cv2.imread(hr_rgb_path)
        print(hr_rgb_img.shape)
        hr_rgb_img = cv2.cvtColor(hr_rgb_img, cv2.COLOR_BGR2RGB)
        return hr_rgb_img.astype(np.float32) / 255.0  # Normalize
    
    def get_lr(self, frame_id):
        """Loads a single LR frame."""

        # files start with index 1 (not 0)
        frame_id+=1

        lr_sample_path = os.path.join(self.lr_dataset, self.area_name, "L2A")
        lr_rgb_path = os.path.join(lr_sample_path, f"{self.area_name}-{frame_id}-L2A_data.tiff")
        lr_rgb_img = tifffile.imread(lr_rgb_path)[:, :, 4:1:-1].copy()  # Select RGB bands and reverse order
        lr_rgb_img = torch.tensor(lr_rgb_img, dtype=torch.float32).clip(0, 1)  # Data is already normalized, but needs to be clipped

        return lr_rgb_img
    
    def __getitem__(self, idx):
        lr_image = self.get_lr(frame_id=idx)  # Shape: (8, lr_img_size, lr_img_size, 3)
        
        # Convert to torch tensors
        lr_image = torch.tensor(lr_image)
        
        return {
            'input': self.hr_coords,
            'lr_target': lr_image,
            'sample_id': idx,
            # note: the true shifts are unknown, set to default 0
            'shifts': {
                'dx_lr': 0,
                'dy_lr': 0,
                'dx_hr': 0,
                'dy_hr': 0,
                'dx_percent': 0,
                'dy_percent': 0
            }
        }
    
    def get_original_hr(self):
        """Return the original image (before any transformations)"""
        return self.hr_image
    
    def get_hr_coordinates(self):
        """Return the high-resolution coordinates."""
        return self.hr_coords
    
    def get_lr_sample(self, index):
        """Get a specific LR sample by index.
        
        Args:
            index: Sample index (0 is the reference sample)
            
        Returns:
            Tensor of shape [C, H, W] with values in [0, 1]
        """
        return self.get_lr(index).permute(2, 0, 1)
    
    def get_lr_sample_hwc(self, index):
        """Get a specific LR sample by index in HWC format.
        
        Args:
            index: Sample index (0 is the reference sample)
            
        Returns:
            Tensor of shape [H, W, C] with values in [0, 1]
        """
        return self.get_lr(index)
    
    def get_lr_mean(self, index):
        """Return mean for unstandardization.
        
        Args:
            index: Sample index
            
        Returns:
            Tensor of shape [3, 1, 1] with zero mean (since no standardization applied)
        """
        return torch.zeros(3, 1, 1)
    
    def get_lr_std(self, index):
        """Return std for unstandardization.
        
        Args:
            index: Sample index
            
        Returns:
            Tensor of shape [3, 1, 1] with unit std (since no standardization applied)
        """
        return torch.ones(3, 1, 1)


class WorldStratTestDataset(torch.utils.data.Dataset):
    """Dataset for worldstrat_test_data with correct directory structure"""
    def __init__(self, data_root, sample_id=None, scale_factor=4, keep_in_memory=True):
        """
        Initialize WorldStratTestDataset for compatibility with benchmark scripts.
        
        Args:
            data_root: Base path to worldstrat test data
            sample_id: Sample name (e.g., "Landcover-1041077")
            scale_factor: Scale factor for HR image
            keep_in_memory: Whether to keep data in memory (ignored)
        """
        if sample_id is None:
            # Default sample name
            sample_id = "Landcover-1041077"
        
        self.data_root = Path(data_root)
        self.sample_id = sample_id
        self.scale_factor = scale_factor

        
        # Set up paths
        self.sample_dir = self.data_root / sample_id
        self.hr_dir = self.sample_dir / "hr"
        self.lr_dir = self.sample_dir / "lr"
        
        # Load high-resolution image
        hr_path = self.hr_dir / f"{sample_id}_rgb.png"
        self.hr_image = self._load_hr_image(hr_path)
        
        # Find all LR images
        self.lr_paths = sorted(list(self.lr_dir.glob(f"{sample_id}-*-rgb.png")))
        self.num_frames = len(self.lr_paths)
        
        # load all lr images
        self.lr_images = []
        for lr_path in self.lr_paths:
            self.lr_images.append(self._load_lr_image(lr_path))
        
        # scale_factor should be set by the ratio between the hr and lr image sizes
        self.scale_factor = self.hr_image.shape[0] / self.lr_images[0].shape[0]
        
        # Create input coordinate grid that matches the HR image
        self.hr_coords = np.linspace(0, 1, self.hr_image.shape[0], endpoint=False)
        self.hr_coords = np.stack(np.meshgrid(self.hr_coords, self.hr_coords), -1)
        self.hr_coords = torch.FloatTensor(self.hr_coords)
    
    def _load_hr_image(self, hr_path):
        """Load and process the high-resolution image."""
        hr_rgb_img = cv2.imread(str(hr_path))
        hr_rgb_img = cv2.cvtColor(hr_rgb_img, cv2.COLOR_BGR2RGB)
        return torch.tensor(hr_rgb_img.astype(np.float32) / 255.0)
    
    def _load_lr_image(self, lr_path):
        """Load a single LR frame."""
        lr_rgb_img = cv2.imread(str(lr_path))
        lr_rgb_img = cv2.cvtColor(lr_rgb_img, cv2.COLOR_BGR2RGB)
        return torch.tensor(lr_rgb_img.astype(np.float32) / 255.0)
    
    def __len__(self):
        return self.num_frames
    
    def __getitem__(self, idx):
        lr_path = self.lr_paths[idx]
        lr_image = self._load_lr_image(lr_path)
        
        return {
            'input': self.hr_coords,
            'lr_target': lr_image,
            'sample_id': idx,
            'scale_factor': self.scale_factor,
            'shifts': {
                'dx_lr': 0,
                'dy_lr': 0,
                'dx_hr': 0,
                'dy_hr': 0,
                'dx_percent': 0,
                'dy_percent': 0
            }
        }
    
    def get_original_hr(self):
        """Return the original HR image"""
        return self.hr_image
    
    def get_hr_coordinates(self):
        """Return the high-resolution coordinates."""
        return self.hr_coords
    
    def get_lr_sample(self, index):
        """Get a specific LR sample by index in CHW format."""
        lr_path = self.lr_paths[index]
        lr_image = self._load_lr_image(lr_path)
        return lr_image.permute(2, 0, 1)
    
    def get_lr_sample_hwc(self, index):
        """Get a specific LR sample by index in HWC format."""
        lr_path = self.lr_paths[index]
        return self._load_lr_image(lr_path)
    
    def get_lr_mean(self, index):
        """Return mean for unstandardization (zeros since no standardization applied)."""
        return torch.zeros(3, 1, 1)
    
    def get_lr_std(self, index):
        """Return std for unstandardization (ones since no standardization applied)."""
        return torch.ones(3, 1, 1)


if __name__ == "__main__":
    print("Testing WorldStratDatasetFrame...")
    
    try:
        # Test with actual data path (you'll need to update this)
        # Example usage:
        test_dataset = WorldStratDatasetFrame(
            data_dir="/path/to/your/worldstrat/data",  # Update this path
            area_name="UNHCR-LBNs006446",  # Update this area name
            num_frames=8,
            hr_size=512
        )
        
        print(f"✅ Dataset created successfully!")
        print(f"Dataset length: {len(test_dataset)}")
        print(f"HR image shape: {test_dataset.get_original_hr().shape}")
        print(f"HR coordinates shape: {test_dataset.get_hr_coordinates().shape}")
        
        # Test getting a sample
        if len(test_dataset) > 0:
            sample = test_dataset[0]
            print(f"Sample keys: {sample.keys()}")
            print(f"Input shape: {sample['input'].shape}")
            print(f"LR target shape: {sample['lr_target'].shape}")
            print(f"Sample ID: {sample['sample_id']}")
            
            # Test the new methods
            print(f"LR sample (CHW) shape: {test_dataset.get_lr_sample(0).shape}")
            print(f"LR sample (HWC) shape: {test_dataset.get_lr_sample_hwc(0).shape}")
            print(f"LR mean shape: {test_dataset.get_lr_mean(0).shape}")
            print(f"LR std shape: {test_dataset.get_lr_std(0).shape}")
            
            print("✅ WorldStratDatasetFrame test completed successfully!")
        
    except Exception as e:
        print(f"❌ WorldStratDatasetFrame test failed: {e}")
        print("\nTo use WorldStratDatasetFrame, you need to:")
        print("1. Update the data_dir path to point to your WorldStrat dataset")
        print("2. Make sure the directory structure is:")
        print("   data_dir/hr_dataset/12bit/area_name/area_name_rgb.png")
        print("   data_dir/lr_dataset/area_name/L2A/area_name-1-L2A_data.tiff")
        print("   data_dir/lr_dataset/area_name/L2A/area_name-2-L2A_data.tiff")
        print("   ...")
    
    print("\n" + "="*60)
    print("HOW TO USE WorldStratDatasetFrame:")
    print("="*60)
    print("""
# 1. Create dataset instance
dataset = WorldStratDatasetFrame(
    data_dir="/path/to/worldstrat/data",  # Base directory
    area_name="UNHCR-LBNs006446",        # Area identifier
    num_frames=8,                        # Number of LR frames
    hr_size=512                          # Optional: resize HR image
)

# 2. Use with DataLoader
from torch.utils.data import DataLoader
dataloader = DataLoader(dataset, batch_size=1, shuffle=False)

# 3. Use in training loop
for batch in dataloader:
    input_coords = batch['input']        # HR coordinates
    lr_target = batch['lr_target']       # LR image
    sample_id = batch['sample_id']       # Frame ID
    shifts = batch['shifts']             # Ground truth shifts (all zeros)

# 4. Access individual methods
hr_image = dataset.get_original_hr()     # Get HR ground truth
hr_coords = dataset.get_hr_coordinates() # Get HR coordinate grid
lr_sample = dataset.get_lr_sample(0)     # Get LR frame 0 (CHW format)
lr_hwc = dataset.get_lr_sample_hwc(0)    # Get LR frame 0 (HWC format)
lr_mean = dataset.get_lr_mean(0)         # Get mean for unstandardization
lr_std = dataset.get_lr_std(0)           # Get std for unstandardization
    """)
    
    print("\n" + "="*60)
    print("COMPATIBILITY WITH BENCHMARK:")
    print("="*60)
    print("✅ WorldStratDatasetFrame is now compatible with benchmark_models.py!")
    print("✅ All required methods are implemented:")
    print("   - get_original_hr()")
    print("   - get_hr_coordinates()")
    print("   - get_lr_sample(index)")
    print("   - get_lr_sample_hwc(index)")
    print("   - get_lr_mean(index)")
    print("   - get_lr_std(index)")
    print("\nYou can now run benchmark_models.py with this dataset!")