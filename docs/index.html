<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Satellite Super Resolution</title>
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }

        body {
            font-family: 'Inter', -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, Oxygen, Ubuntu, Cantarell, sans-serif;
            line-height: 1.6;
            color: #333;
            background-color: #fff;
        }

        .container {
            max-width: 1200px;
            margin: 0 auto;
            padding: 0 40px;
        }

        /* Header */
        header {
            padding: 80px 0 60px;
            text-align: center;
            border-bottom: 1px solid #e0e0e0;
        }

        h1 {
            font-size: 48px;
            font-weight: 700;
            color: #1a1a1a;
            margin-bottom: 20px;
            letter-spacing: -0.02em;
        }

        .authors {
            font-size: 18px;
            color: #666;
            margin-bottom: 30px;
        }

        .links {
            display: flex;
            justify-content: center;
            gap: 20px;
            flex-wrap: wrap;
        }

        .link-button {
            display: inline-block;
            padding: 10px 24px;
            background-color: #1a1a1a;
            color: white;
            text-decoration: none;
            border-radius: 4px;
            font-weight: 500;
            transition: background-color 0.3s;
        }

        .link-button:hover {
            background-color: #333;
        }

        .link-button.secondary {
            background-color: #fff;
            color: #1a1a1a;
            border: 1px solid #1a1a1a;
        }

        .link-button.secondary:hover {
            background-color: #f5f5f5;
        }

        /* Hero Image */
        .hero-image {
            margin: 60px 0;
            text-align: center;
        }

        .hero-image img {
            max-width: 100%;
            height: auto;
            border-radius: 8px;
            box-shadow: 0 4px 20px rgba(0,0,0,0.1);
        }

        /* Sections */
        section {
            margin: 80px 0;
        }

        h2 {
            font-size: 32px;
            font-weight: 700;
            color: #1a1a1a;
            margin-bottom: 30px;
            letter-spacing: -0.01em;
        }

        h3 {
            font-size: 24px;
            font-weight: 600;
            color: #1a1a1a;
            margin-top: 40px;
            margin-bottom: 20px;
        }

        p {
            font-size: 18px;
            color: #444;
            margin-bottom: 20px;
            line-height: 1.8;
        }

        /* Abstract */
        .abstract {
            background-color: #f8f9fa;
            padding: 40px;
            border-radius: 8px;
            margin: 40px 0;
            border-left: 4px solid #1a1a1a;
        }

        .abstract p {
            margin-bottom: 0;
        }

        /* Method/Approach */
        .method-grid {
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(300px, 1fr));
            gap: 30px;
            margin: 40px 0;
        }

        .method-item {
            padding: 30px;
            background-color: #f8f9fa;
            border-radius: 8px;
        }

        .method-item h4 {
            font-size: 20px;
            font-weight: 600;
            margin-bottom: 15px;
            color: #1a1a1a;
        }

        .method-item p {
            font-size: 16px;
            color: #666;
        }

        /* Results */
        .results-grid {
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(300px, 1fr));
            gap: 30px;
            margin: 40px 0;
        }

        .result-item {
            text-align: center;
        }

        .result-item img {
            width: 100%;
            height: auto;
            border-radius: 8px;
            box-shadow: 0 2px 10px rgba(0,0,0,0.1);
            margin-bottom: 15px;
        }

        .result-item h4 {
            font-size: 18px;
            font-weight: 600;
            color: #1a1a1a;
            margin-bottom: 10px;
        }

        .result-item p {
            font-size: 14px;
            color: #666;
        }

        /* Code Block */
        pre {
            background-color: #1a1a1a;
            color: #f8f9fa;
            padding: 24px;
            border-radius: 8px;
            overflow-x: auto;
            margin: 30px 0;
            font-size: 14px;
            line-height: 1.6;
        }

        code {
            font-family: 'Monaco', 'Menlo', 'Ubuntu Mono', monospace;
        }

        /* Table */
        table {
            width: 100%;
            border-collapse: collapse;
            margin: 30px 0;
        }

        th, td {
            padding: 12px 16px;
            text-align: left;
            border-bottom: 1px solid #e0e0e0;
        }

        th {
            background-color: #f8f9fa;
            font-weight: 600;
            color: #1a1a1a;
        }

        tr:hover {
            background-color: #f8f9fa;
        }

        /* Lists */
        ul, ol {
            margin-left: 30px;
            margin-bottom: 20px;
        }

        li {
            font-size: 18px;
            color: #444;
            margin-bottom: 10px;
            line-height: 1.8;
        }

        /* Footer */
        footer {
            text-align: center;
            padding: 60px 0;
            margin-top: 80px;
            border-top: 1px solid #e0e0e0;
            color: #666;
        }

        /* Responsive */
        @media (max-width: 768px) {
            .container {
                padding: 0 20px;
            }

            h1 {
                font-size: 36px;
            }

            h2 {
                font-size: 28px;
            }

            section {
                margin: 60px 0;
            }

            .abstract {
                padding: 24px;
            }

            .method-grid,
            .results-grid {
                grid-template-columns: 1fr;
            }
        }
    </style>
</head>
<body>
    <div class="container">
        <header>
            <h1>Satellite Super Resolution</h1>
            <p class="authors">Self-supervised super-resolution using coordinate-based MLPs</p>
            <div class="links">
                <a href="https://github.com/yourusername/satellite_sr" class="link-button">Code</a>
                <a href="#" class="link-button secondary">Paper</a>
            </div>
        </header>

        <div class="hero-image">
            <img src="../images/hr_image.png" alt="Satellite Super Resolution Results" onerror="this.style.display='none'">
        </div>

        <section>
            <h2>Abstract</h2>
            <div class="abstract">
                <p>
                    We present a self-supervised approach for satellite image super-resolution that learns 
                    sub-pixel transformations from low-resolution (LR) images using coordinate-based Multi-Layer 
                    Perceptrons (MLPs). Our method overfits and optimizes a Coordinate-based MLP to learn the 
                    sub-pixel transformations in the LR images from a HR image and upsample it. This approach 
                    eliminates the need for paired training data and enables high-quality super-resolution through 
                    the exploitation of sub-pixel translations in multiple LR views of the same scene.
                </p>
            </div>
        </section>

        <section>
            <h2>Method</h2>
            <p>
                Our approach consists of several key components:
            </p>

            <div class="method-grid">
                <div class="method-item">
                    <h4>1. Data Generation</h4>
                    <p>
                        Start with an original HR image, upsample it, apply random translations, 
                        and create HR-LR pairs with tracked transformation parameters.
                    </p>
                </div>
                <div class="method-item">
                    <h4>2. Coordinate-based MLP</h4>
                    <p>
                        Use a neural network that takes spatial coordinates as input and outputs 
                        pixel values, enabling sub-pixel learning of transformations.
                    </p>
                </div>
                <div class="method-item">
                    <h4>3. Self-supervised Learning</h4>
                    <p>
                        Optimize the network to learn transformations from multiple LR views, 
                        leveraging the known sub-pixel translations between images.
                    </p>
                </div>
            </div>

            <h3>Data Generation Flow</h3>
            <ol>
                <li><strong>Start with Original HR Image</strong> - Input: Original HR image (e.g., 256×256)</li>
                <li><strong>Upsampling Phase</strong> - Double the size of original image (512×512) using bilinear interpolation</li>
                <li><strong>Translation Phase</strong> - Generate 16 different random translations between -6 and +6 pixels in both x and y directions</li>
                <li><strong>HR-LR Pair Creation</strong> - For each translated upsampled image, downsample to create HR (256×256) and LR (64×64) pairs using AREA interpolation</li>
                <li><strong>Data Organization</strong> - Save LR images, HR images, and transformation parameters in JSON format</li>
            </ol>
        </section>

        <section>
            <h2>Results</h2>
            <p>
                Our method successfully learns sub-pixel transformations and produces high-quality 
                super-resolved images. Results are saved with comparison visualizations, training 
                curves, and performance metrics.
            </p>
            <div class="results-grid">
                <div class="result-item">
                    <img src="../images/hr_image.png" alt="High Resolution Output" onerror="this.style.display='none'">
                    <h4>Super-Resolved Output</h4>
                    <p>High-quality upsampled image</p>
                </div>
                <div class="result-item">
                    <img src="../images/hr_image.png" alt="Comparison" onerror="this.style.display='none'">
                    <h4>Model Comparison</h4>
                    <p>Visualization of different models</p>
                </div>
                <div class="result-item">
                    <img src="../images/hr_image.png" alt="Training Curves" onerror="this.style.display='none'">
                    <h4>Training Progress</h4>
                    <p>Loss and metrics over time</p>
                </div>
            </div>
        </section>

        <section>
            <h2>Quick Start</h2>
            <h3>Installation</h3>
            <pre><code>git clone https://github.com/yourusername/satellite_sr.git
cd satellite_sr
pip install -r requirements.txt</code></pre>

            <h3>Generate Training Data</h3>
            <pre><code>python create_data_from_single_image.py --input_image path/to/image.png --output_dir data/sample_1</code></pre>

            <h3>Training</h3>
            <pre><code>python main.py --dataset satburst_synth --sample_id sample_1 --df 4 --lr_shift 1.0 --iters 1000 --d 0</code></pre>
        </section>

        <section>
            <h2>Key Parameters</h2>
            <table>
                <thead>
                    <tr>
                        <th>Parameter</th>
                        <th>Description</th>
                        <th>Default</th>
                    </tr>
                </thead>
                <tbody>
                    <tr>
                        <td><code>--dataset</code></td>
                        <td>Dataset type: "satburst_synth", "worldstrat", "burst_synth"</td>
                        <td>"satburst_synth"</td>
                    </tr>
                    <tr>
                        <td><code>--df</code></td>
                        <td>Downsampling factor</td>
                        <td>4</td>
                    </tr>
                    <tr>
                        <td><code>--model</code></td>
                        <td>Model type: "mlp", "siren", "wire", "linear", "conv", "thera"</td>
                        <td>"mlp"</td>
                    </tr>
                    <tr>
                        <td><code>--input_projection</code></td>
                        <td>Input projection: "linear", "fourier_10", "legendre", "none"</td>
                        <td>"fourier_10"</td>
                    </tr>
                    <tr>
                        <td><code>--iters</code></td>
                        <td>Number of training iterations</td>
                        <td>1000</td>
                    </tr>
                    <tr>
                        <td><code>--lr_shift</code></td>
                        <td>Low-resolution shift amount</td>
                        <td>1.0</td>
                    </tr>
                </tbody>
            </table>
        </section>

        <section>
            <h2>Citation</h2>
            <pre><code>@misc{satellite_sr,
  title={Satellite Super Resolution},
  author={Your Name},
  year={2024},
  howpublished={\url{https://github.com/yourusername/satellite_sr}}
}</code></pre>
        </section>

        <footer>
            <p>&copy; 2024 Satellite Super Resolution Project</p>
        </footer>
    </div>
</body>
</html>
